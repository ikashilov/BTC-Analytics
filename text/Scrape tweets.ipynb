{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from Twitter using Advanced search API (twitter_bot_scaraper wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            ARGS\n",
    "-t, --hashtags, nargs='*', help='Hashtags'  \n",
    "-w, --key_words, nargs='*', help=\"Key words\"  \n",
    "-s, --start_date, help=\"Start date in format YYYY-MM-DD\"  \n",
    "-e, --end_date, help=\"End date in format YYYY-MM-DD\"  \n",
    "-l, --lang, default='en', help='Language'  \n",
    "-c, --scroll_numb, default=100, help=\"Times to scroll the page down\"  \n",
    "-d, --sleep_time, default=1, help=\"Delay for page to download\"  \n",
    "-o, --output_fname, default='output.csv', help=\"Output file name\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example section playground**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run twitter_bot.py -t btc -w bitcoin -s 2019-11-01 -e 2019-12-03 -c 10 -d 2 -o ./output/test_output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#data = pd.read_csv('output.csv', parse_dates=True, index_col='date', encodeing='utf-8')\n",
    "data = pd.read_csv('./output/test_output.csv', encoding='utf-8')\n",
    "data = data.sort_values(by='date')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day by scraping: generate day pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "start_date = dt.date(2018, 12, 1)\n",
    "end_date = dt.date(2019, 12, 1)\n",
    "\n",
    "date_range = [dt.date.fromordinal(i) for i in range(start_date.toordinal(), end_date.toordinal()+1)]\n",
    "# to str\n",
    "date_range = [date.strftime(\"%Y-%m-%d\") for date in date_range]\n",
    "\n",
    "date_pairs = list(zip(date_range, date_range[1:] + date_range[:1]))[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meet: Twitter bot scraper itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import requests\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "\n",
    "# =============================================================================================\n",
    "#                                      PARSE\n",
    "# =============================================================================================\n",
    "def generate_query(key_words, hashtags, start_date, end_date, lang='en'):\n",
    "    first_part=\"https://twitter.com/search?l=\"+lang+\"&q=\"\n",
    "\n",
    "    s0 = \"\"\n",
    "    for word in key_words:\n",
    "        s0 += word+\"%20\"\n",
    "    s0+=\"%23\"\n",
    "\n",
    "    s1 = \"\"\n",
    "    for hst in hashtags[:-1]:\n",
    "        s1 += hst+\"%20OR%20%23\"\n",
    "    s1 += hashtags[-1]+\"%20\"\n",
    "\n",
    "    second_part = \"since%3A\"+start_date+\"%20until%3A\"+end_date+\"&src=typd\"\n",
    "\n",
    "    return first_part+s0+s1+second_part\n",
    "\n",
    "\n",
    "def dowload_page(query, scroll_numb, delay=1, proxy_flag=False):\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--headless')\n",
    "\n",
    "    if proxy_flag:\n",
    "        profile = get_proxy_profile(host, port)\n",
    "        driver = webdriver.Firefox(executable_path='./geckodriver', firefox_profile=profile, options=options)\n",
    "    else:\n",
    "        driver = webdriver.Firefox(executable_path='./geckodriver', options=options)\n",
    "\n",
    "    driver.get(query)\n",
    "\n",
    "    prev_h = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "    for i in range(scroll_numb):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        #driver.implicitly_wait(3)\n",
    "        sleep(delay)\n",
    "        #while driver.execute_script('return document.readyState;') != 'complete':\n",
    "            #sleep(0.1)\n",
    "\n",
    "        cur_h = driver.execute_script(\"return document.body.scrollHeight;\")\n",
    "        if prev_h == cur_h:\n",
    "            #print(\"Stopped at {} iter\".format(i))\n",
    "            break\n",
    "\n",
    "    with open('page.html','w') as f:\n",
    "        f.write(str(driver.page_source.encode('utf-8')))\n",
    "        f.close()\n",
    "\n",
    "    driver.close()\n",
    "    return 0\n",
    "\n",
    "\n",
    "def __process_tweet(tweet):\n",
    "    tweet_div = tweet.find('div', 'tweet')\n",
    "    if not tweet_div:\n",
    "        return None\n",
    "    try:\n",
    "        # --- text\n",
    "        soup_html = tweet.find('div', 'js-tweet-text-container').find('p', 'tweet-text')       \n",
    "        text = soup_html.text\n",
    "        \n",
    "        # --- time\n",
    "        timestamp_epochs = int(tweet.find('span', '_timestamp')['data-time'])\n",
    "        timestamp = datetime.utcfromtimestamp(timestamp_epochs)\n",
    "\n",
    "        action_div = tweet_div.find('div', 'ProfileTweet-actionCountList')\n",
    "\n",
    "        # --- likes\n",
    "        likes = int(action_div.find('span', 'ProfileTweet-action--favorite') \\\n",
    "                              .find('span', 'ProfileTweet-actionCount')['data-tweet-stat-count'] or '0')\n",
    "        # --- retweets\n",
    "        retweets = int(action_div.find('span', 'ProfileTweet-action--retweet') \\\n",
    "                                 .find('span', 'ProfileTweet-actionCount')['data-tweet-stat-count'] or '0')\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "\n",
    "    return [timestamp, text, likes, retweets]\n",
    "\n",
    "\n",
    "\n",
    "def parse_page():\n",
    "    with open('page.html') as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    tweets = soup.find_all('li', 'js-stream-item')\n",
    "\n",
    "    hooy = []\n",
    "    for tweet in tweets:\n",
    "        t = __process_tweet(tweet)\n",
    "        if t:\n",
    "            hooy.append(t)\n",
    "    return hooy\n",
    "\n",
    "\n",
    "# ===================================================================================================\n",
    "#                                MAIN\n",
    "# ===================================================================================================\n",
    "def HOOY(key_words, hashtags, start_date, end_date, \n",
    "         lang='en', scroll_numb=100, sleep_time=1, output_fname='output.csv'):\n",
    "\n",
    "    query = generate_query(key_words=key_words, \n",
    "                           hashtags=hashtags,\n",
    "                           start_date=start_date,\n",
    "                           end_date=end_date,\n",
    "                           lang=lang)\n",
    "\n",
    "    stat = dowload_page(query=query, delay=sleep_time, scroll_numb=scroll_numb)\n",
    "    lst = parse_page()\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(lst, columns=[\"date\", \"text\", \"likes\", \"retweets\"])\n",
    "    df.to_csv(output_fname, header=True, index=False, encoding='utf-8')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.866666666666666"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate approx time\n",
    "24*2*365 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 365/365 [6:53:28<00:00, 67.97s/it]     \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "KEY_WORDS = ['bitcoin', 'btc']\n",
    "HASHTAGS = ['bitcoin', 'btc', 'cryptocurrency', 'crypto', 'finance', 'news']\n",
    "\n",
    "frames = []\n",
    "for i, (BEG, END) in enumerate(tqdm(date_pairs)):\n",
    "    FNAME = './output/pairwise/btc_day{}.csv'.format(i)\n",
    "    df = HOOY(KEY_WORDS, HASHTAGS, BEG, END, sleep_time=2, scroll_numb=24, output_fname=FNAME, lang='en')\n",
    "    frames.append(df)\n",
    "    \n",
    "    \n",
    "df_total = pd.concat(frames)\n",
    "df_total.to_csv('./output/btc_year_full.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat(frames)\n",
    "df_total.to_csv('./output/btc_year_full.csv', header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38266.000000</td>\n",
       "      <td>38266.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.330293</td>\n",
       "      <td>9.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>111.684119</td>\n",
       "      <td>58.673785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5368.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              likes      retweets\n",
       "count  38266.000000  38266.000000\n",
       "mean      26.330293      9.237600\n",
       "std      111.684119     58.673785\n",
       "min        0.000000      0.000000\n",
       "25%        1.000000      0.000000\n",
       "50%        3.000000      1.000000\n",
       "75%       14.000000      4.000000\n",
       "max     5368.000000   5316.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
